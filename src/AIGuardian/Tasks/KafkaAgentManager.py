
from kafka import KafkaProducer, KafkaConsumer
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any
import logging
from a2a.types import (
    AgentAuthentication,
    AgentCapabilities,
    AgentCard,
    AgentSkill,
    TaskState,
)

# Internal Package Imports
from src.AIGuardian.Tasks.Task import Task
from src.AIGuardian.AIDataModels.AILogs import TaskArtifact, TaskCompleted, LLMRequest
from src.MetaFort.AILoggingTopics import AILoggingTopics
from src.MetaFort.SysLogs.KafkaEngine import KafkaEngine
from src.AIGuardian.Tasks.DataStructCreate import DataStructCreate
from src.AIGuardian.Tasks.TaskRegistry import TaskRegistry

class KafkaAgentManager():
    def __init__(self, db_engine=None, end_processing: int=300, mode='strict'):
        self.manager_id = uuid.uuid4()
        self.end_processing = end_processing
        self.mode = mode  # 'strict' or 'warning'
        self.db_engine = db_engine if db_engine else KafkaEngine.default_builder()
        self.task_queue = []
        self.waiting_tasks = []
        self.start_time = datetime.now()
        self.end_time = None
        self.last_processed_time = datetime.now()

        logging.basicConfig(
            filename=f'F:\Airflow_Test\DragonGenLogs\kafka_agent_{self.start_time.strftime("%Y_%m_%d_%H_%M_%S_%f")}.log',  # Output to file
            filemode='w',        # 'w' to overwrite, 'a' to append
            level=logging.DEBUG,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        self.logger = logging.getLogger(__name__)

    def submit_task(self, task, user_prompt=None):
        """
        Submit a task to the Kafka topic.
        """
        # Create a task log entry
        task.input_artifacts['user_prompt'] = user_prompt
        self.db_engine.insert(topic=AILoggingTopics.AI_TASK_TOPIC, data=task)
        self.task_log(task=task, step_status='TASK SUBMITTED')

    def wait_on_task(self, task_id, timeout=180):
        """
        Wait for the Task to complete before proceeding. This task is for a gerneral wait not for a looping manager.
        """
        # This method should look at the completed topic for finished tasks or failed tasks.
        start_time = datetime.now()
        
        # One time use Kafka Consumer with no group_id
        temp_kc = KafkaConsumer(
                    AILoggingTopics.AI_TASK_COMPLETED_TOPIC,
                    bootstrap_servers=[self.db_engine.connection_string],
                    auto_offset_reset='latest')

        task_completed = False
        output_params = {}
        while not task_completed and (datetime.now() - start_time).total_seconds() < timeout:
            completed_tasks = temp_kc.poll(timeout_ms=1000, max_records=10)
            completed_tasks_list = self.kafka_records_to_list(completed_tasks, key='task_id')
            completed_tasks_dict = self.kafka_records_to_dict(completed_tasks, key='task_id', val='output_artifacts')
            if task_id in completed_tasks_list:
                task_completed = True
                print(f"==> Task {task_id} completed.")
                return completed_tasks_dict.get(task_id)

    def task_log(self, task, task_state=TaskState.working, step_status=None, error_code=None, error_message=None):
        """
        Log the task to the backend kafka task log topic.
        """
        # Create a task log entry
        task_log_entry = task.update_task_log(task_state, step_status, error_code, error_message)
        self.db_engine.insert(topic=AILoggingTopics.AI_TASK_LOG_TOPIC, data=task_log_entry)

    def add_task_to_queue(self, task):
        # TODO move decoding to the KafkaEngine
        if not isinstance(task.value, dict):
            task_json = json.loads(task.value.decode('utf-8'))
        else:
            task_json = task.value
        # TODO add try-except around construction of the task object
        task = TaskRegistry.build_from_json(task_json, self.db_engine)
        self.task_log(task=task, step_status='TASK PICKED UP')
        self.task_queue.append(task)

    def publish(self, artifacts: List[Any]):
        """
        Publish any new artifacts generated by the Task.
        """
        if not artifacts:
            self.logger.warning("No artifacts to publish.")
            return
        for artifact in artifacts:
            if isinstance(artifact, Task):
                artifact = self.submit_task(artifact)
            elif isinstance(artifact, TaskArtifact):
                self.db_engine.insert(topic=AILoggingTopics.AI_TASK_ARTIFACTS_TOPIC, data=artifact)
                self.logger.info(f"Published artifact: {artifact}")
            elif isinstance(artifact, TaskCompleted):
                self.db_engine.insert(topic=AILoggingTopics.AI_TASK_COMPLETED_TOPIC, data=artifact)
            elif isinstance(artifact, LLMRequest):
                self.db_engine.insert(topic=AILoggingTopics.AI_REQUEST_LOG_TOPIC, data=artifact)
            else:
                error_suffix = 'Skipping publication.' if self.mode != 'strict' else 'Raising ValueError.'
                self.logger.warning(f"Unsupported artifact type: {type(artifact)}. {error_suffix}")
                if self.mode == 'strict':
                    raise ValueError(f"Unsupported artifact type: {type(artifact)}. {error_suffix}")
                continue

    def check_waiting_tasks(self):
        """
        Check if there are any waiting tasks and process them.
        This method is called periodically to check for completed tasks.
        """
        if not self.waiting_tasks:
            return
        
        completed_tasks = self.db_engine.consumers[AILoggingTopics.AI_TASK_COMPLETED_TOPIC].poll(timeout_ms=1000, max_records=20)
        completed_tasks_json = self.kafka_records_to_list(completed_tasks, key='ALL')
        completed_task_objects = [TaskCompleted(**task_json) for task_json in completed_tasks_json]

        # Check for new Artifacts
        new_artifacts = self.db_engine.consumers[AILoggingTopics.AI_TASK_ARTIFACTS_TOPIC].poll(timeout_ms=1000, max_records=20)
        new_artifacts_json = self.kafka_records_to_list(new_artifacts, key='ALL')
        new_artifacts_objects = [TaskCompleted(**task_json) for task_json in new_artifacts_json]
        
        # Iterate through the completed tasks and check dependencies
        for objects in [*completed_task_objects, *new_artifacts_objects]:
            for waiting_task in self.waiting_tasks:
                waiting_task.check_dependency(objects)
        
        # check if any task is done waiting
        tasks_to_remove = []
        for task in self.waiting_tasks:
            if not task.is_waiting():
                tasks_to_remove.append(task)
                self.task_log(task=task, step_status='TASK DONE WAITING')
        
        # Remove the completed task after iterating through it
        for r_task in tasks_to_remove:
            self.waiting_tasks.remove(r_task)

    def cycle(self):
        """
        The main loop for the Kafka Agent Manager. This will run until the end_processing time is reached.
        """
        agent_loop_cnt = 0

        while (datetime.now() - self.last_processed_time).total_seconds() < self.end_processing:
            print(f"Agent Loop Count: {agent_loop_cnt} and last consumed time: {self.last_processed_time}")
            agent_loop_cnt += 1
            # Grab records from the Kafka topic (This is under the universal consumer group_id = action-agent)
            task_queue = self.db_engine.consumers[AILoggingTopics.AI_TASK_TOPIC].poll(timeout_ms=1000, max_records=3)
            for topic_partition, messages in task_queue.items():
                for message in messages:
                    self.add_task_to_queue(message)
            
            # Run the task polled by the Kafka consumer
            for task_item in self.task_queue:
                self.logger.info(f"==> Task: {task_item.name} ==> {task_item.task_id}")
                self.task_log(task=task_item, step_status='TASK RUNNING')
                task_item.run()
                self.task_log(task=task_item, step_status='TASK RUNNING DONE')
                # Submit any generated tasks
                self.publish(task_item.publish_artifacts())
                # Check if needs to wait
                if task_item.is_waiting():
                    self.waiting_tasks.append(task_item)
                    self.task_log(task=task_item, step_status='TASK WAITING')
                elif task_item.is_completed:
                    self.task_queue.remove(task_item)
                self.last_processed_time = datetime.now()

            # Check in on waiting tasks
            self.check_waiting_tasks()

        print("End of processing")
        self.end_time = datetime.now()
        # self.db_engine.close()

    # region Utility Methods
    # TODO move this to the KafkaEngine
    def kafka_records_to_list(self, records, key):
        kcr_list = []
        for topic_partition, c_messages in records.items():
            for c_message in c_messages:
                if not isinstance(c_message.value, dict):
                    task_json = json.loads(c_message.value.decode('utf-8'))
                else:
                    task_json = c_message.value
                # Allow for the user to specify a key or ALL to get the whole dictionary message
                if key == 'ALL':
                    kcr_list.append(task_json)
                else:
                    kcr_list.append(task_json.get(key))
        return kcr_list
    
    # TODO move this to the KafkaEngine
    def kafka_records_to_dict(self, records, key, val):
        kcr_dict = {}
        for topic_partition, c_messages in records.items():
            for c_message in c_messages:
                if not isinstance(c_message.value, dict):
                    task_json = json.loads(c_message.value.decode('utf-8'))
                else:
                    task_json = c_message.value
                # Allow for the user to specify a key or ALL to get the whole dictionary message
                if val == 'ALL':
                    kcr_dict[task_json.get(key)] = task_json
                else:
                    kcr_dict[task_json.get(key)] = task_json.get(val)
        return kcr_dict
    # endregion Utility Methods