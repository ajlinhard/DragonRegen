{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "s_raw_root_path = r'F:\\DataSamples\\DataSets'\n",
    "s_spark_file_server_root = r'F:\\Spark_Data_Test'\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Prep Census Data') \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", s_spark_file_server_root) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+--------+--------+------------+--------+--------+------+-------+---------+-----------+\n",
      "|name           |rank|count   |prop100k|cum_prop100k|pctwhite|pctblack|pctapi|pctaian|pct2prace|pcthispanic|\n",
      "+---------------+----+--------+--------+------------+--------+--------+------+-------+---------+-----------+\n",
      "|ALL OTHER NAMES|0   |29312001|9936.97 |9936.97     |66.65   |8.53    |7.97  |0.86   |2.32     |13.67      |\n",
      "|SMITH          |1   |2442977 |828.19  |828.19      |70.9    |23.11   |0.5   |0.89   |2.19     |2.4        |\n",
      "|JOHNSON        |2   |1932812 |655.24  |1483.42     |58.97   |34.63   |0.54  |0.94   |2.56     |2.36       |\n",
      "|WILLIAMS       |3   |1625252 |550.97  |2034.39     |45.75   |47.68   |0.46  |0.82   |2.81     |2.49       |\n",
      "|BROWN          |4   |1437026 |487.16  |2521.56     |57.95   |35.6    |0.51  |0.87   |2.55     |2.52       |\n",
      "|JONES          |5   |1425470 |483.24  |3004.8      |55.19   |38.48   |0.44  |1      |2.61     |2.29       |\n",
      "|GARCIA         |6   |1166120 |395.32  |3400.12     |5.38    |0.45    |1.41  |0.47   |0.26     |92.03      |\n",
      "|MILLER         |7   |1161437 |393.74  |3793.86     |84.11   |10.76   |0.54  |0.66   |1.77     |2.17       |\n",
      "|DAVIS          |8   |1116357 |378.45  |4172.31     |62.2    |31.6    |0.49  |0.82   |2.45     |2.44       |\n",
      "|RODRIGUEZ      |9   |1094924 |371.19  |4543.5      |4.75    |0.54    |0.57  |0.18   |0.18     |93.77      |\n",
      "+---------------+----+--------+--------+------------+--------+--------+------+-------+---------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Files\n",
    "df_census_surname = spark.read \\\n",
    "    .options(header='true', delimiter=',', inferSchema=True) \\\n",
    "    .csv(os.path.join(s_raw_root_path, 'Census_Surnames\\\\Names_2010Census.csv'))\n",
    "\n",
    "df_census_surname.orderBy('rank', ascending=True).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160975"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census_surname.select(max('rank')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a upper bound for cumulative distribution function\n",
    "df_census = df_census_surname.filter(col('name') != 'ALL OTHER NAMES') \\\n",
    "    .withColumn('unqiue_rank', row_number().over(Window.orderBy('cum_prop100k'))) \\\n",
    "    .withColumn('cum_prop100k', (col('cum_prop100k') * 100).cast(IntegerType()))\n",
    "\n",
    "df_join = df_census.alias('high').join(df_census.alias('low'), on= col('low.unqiue_rank') == col('high.unqiue_rank') - 1, how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------------+-----------------+\n",
      "|     name|unqiue_rank|cum_prop100k_low|cum_prop100k_high|\n",
      "+---------+-----------+----------------+-----------------+\n",
      "|    SMITH|          1|               0|            82819|\n",
      "|  JOHNSON|          2|           82819|           148342|\n",
      "| WILLIAMS|          3|          148342|           203439|\n",
      "|    BROWN|          4|          203439|           252156|\n",
      "|    JONES|          5|          252156|           300480|\n",
      "|   GARCIA|          6|          300480|           340012|\n",
      "|   MILLER|          7|          340012|           379386|\n",
      "|    DAVIS|          8|          379386|           417231|\n",
      "|RODRIGUEZ|          9|          417231|           454350|\n",
      "| MARTINEZ|         10|          454350|           490289|\n",
      "+---------+-----------+----------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----------+-----------+----------------+-----------------+\n",
      "|       name|unqiue_rank|cum_prop100k_low|cum_prop100k_high|\n",
      "+-----------+-----------+----------------+-----------------+\n",
      "|      OTHER|     162254|         9006303|         10000000|\n",
      "|    DORIOTT|     162253|         9006299|          9006303|\n",
      "|     DONLEA|     162252|         9006296|          9006299|\n",
      "|      DOKAS|     162251|         9006293|          9006296|\n",
      "|  DIETZMANN|     162250|         9006289|          9006293|\n",
      "|     DOBBEN|     162249|         9006286|          9006289|\n",
      "|     DOBRON|     162248|         9006283|          9006286|\n",
      "| DITERLIZZI|     162247|         9006279|          9006283|\n",
      "| DIFILLIPPO|     162246|         9006276|          9006279|\n",
      "|DONNERMEYER|     162245|         9006272|          9006276|\n",
      "+-----------+-----------+----------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = df_join.select(\n",
    "    coalesce(col('high.name'),lit('OTHER')).alias('name'),\n",
    "    coalesce(col('high.unqiue_rank'),col('low.unqiue_rank')+1).alias('unqiue_rank'),\n",
    "    ifnull(col('low.cum_prop100k'), lit(0)).alias('cum_prop100k_low'),\n",
    "    ifnull(col('high.cum_prop100k'), lit(10_000_000)).alias('cum_prop100k_high'),\n",
    ")\n",
    "\n",
    "df_join.orderBy(col('cum_prop100k_low'), ascending=True\n",
    ").show(10)\n",
    "df_join.orderBy(col('cum_prop100k_low'), ascending=False\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.withColumnRenamed('name','last_name').withColumnRenamed('cum_prop100k_low','profile_lower_bound').withColumnRenamed('cum_prop100k_high','profile_upper_bound') \\\n",
    "    .write.mode('overwrite').parquet(os.path.join(s_spark_file_server_root, 'census_surname_bounds.parquet'))\n",
    "# df_join.write.mode('overwrite').saveAsTable('census_surname_bounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------------+-------------------+\n",
      "|last_name|unqiue_rank|profile_lower_bound|profile_upper_bound|\n",
      "+---------+-----------+-------------------+-------------------+\n",
      "|SMITH    |1          |0                  |82819              |\n",
      "|JOHNSON  |2          |82819              |148342             |\n",
      "|WILLIAMS |3          |148342             |203439             |\n",
      "|BROWN    |4          |203439             |252156             |\n",
      "|JONES    |5          |252156             |300480             |\n",
      "|GARCIA   |6          |300480             |340012             |\n",
      "|MILLER   |7          |340012             |379386             |\n",
      "|DAVIS    |8          |379386             |417231             |\n",
      "|RODRIGUEZ|9          |417231             |454350             |\n",
      "|MARTINEZ |10         |454350             |490289             |\n",
      "+---------+-----------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "162254\n",
      "162254\n"
     ]
    }
   ],
   "source": [
    "# reload test\n",
    "df_first_names = spark.read.parquet(r'F:\\Spark_Data_Test\\census_surname_bounds.parquet')\n",
    "df_first_names.show(10, truncate=False)\n",
    "# Check count matches on reload\n",
    "print(df_first_names.count())\n",
    "print(df_join.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.withColumnRenamed('name','first_name').withColumnRenamed('cum_prop100k_low','profile_lower_bound').withColumnRenamed('cum_prop100k_high','profile_upper_bound') \\\n",
    "    .write.mode('overwrite').parquet(os.path.join(s_spark_file_server_root, 'census_firstname_bounds.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "+--------+\n",
      "|name_int|\n",
      "+--------+\n",
      "| 5713313|\n",
      "|  849722|\n",
      "| 3755173|\n",
      "| 8112786|\n",
      "| 1929916|\n",
      "| 3493837|\n",
      "| 1589411|\n",
      "| 8082121|\n",
      "| 6311311|\n",
      "| 7878448|\n",
      "+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.DataCreator.DataGenerators.PyData import PyData\n",
    "\n",
    "li_name_lkp = PyData.random_ints(1000, 1, 10_000_000)\n",
    "print(type(li_name_lkp))\n",
    "schema = StructType([StructField('name_int', IntegerType(), False)])\n",
    "df_new_names = spark.createDataFrame(zip(li_name_lkp), schema)\n",
    "df_new_names.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+----------------+-----------------+\n",
      "|name_int|       name|unqiue_rank|cum_prop100k_low|cum_prop100k_high|\n",
      "+--------+-----------+-----------+----------------+-----------------+\n",
      "| 5713313|  MCFARLANE|       3795|         5713182|          5713498|\n",
      "|  849722|      WHITE|         24|          830208|           852599|\n",
      "| 3755173|    ENGLISH|        748|         3754501|          3756074|\n",
      "| 8112786|STANCHFIELD|      40510|         8112777|          8112795|\n",
      "| 1929916|     BRYANT|        128|         1924103|          1930639|\n",
      "| 3493837|     DECKER|        597|         3492033|          3493951|\n",
      "| 1589411|     CHAVEZ|         83|         1587366|          1595871|\n",
      "| 8082121|      JOBST|      38877|         8082113|          8082132|\n",
      "| 6311311|       SENN|       6273|         6311249|          6311434|\n",
      "| 7878448|     ELISON|      29856|         7878437|          7878463|\n",
      "+--------+-----------+-----------+----------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_name_w_str = df_new_names.join(df_join, on= (df_new_names.name_int > df_join.cum_prop100k_low) & (df_new_names.name_int <= df_join.cum_prop100k_high), how='left')\n",
    "df_new_name_w_str.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|count(1)|count(DISTINCT name)|\n",
      "+--------+--------------------+\n",
      "|1000    |766                 |\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_name_w_str.select(count('*'), countDistinct('name')).show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|name     |name_cnt|\n",
      "+---------+--------+\n",
      "|OTHER    |82      |\n",
      "|JOHNSON  |10      |\n",
      "|SMITH    |9       |\n",
      "|ANDERSON |9       |\n",
      "|DAVIS    |8       |\n",
      "|BROWN    |8       |\n",
      "|JONES    |6       |\n",
      "|GARCIA   |6       |\n",
      "|MOORE    |6       |\n",
      "|HERNANDEZ|6       |\n",
      "+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_name_w_str.groupBy('name').agg(count('*').alias('name_cnt')).orderBy('name_cnt', ascending=False).show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
