{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd0802e",
   "metadata": {},
   "source": [
    "## Working with making schemas from JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45be7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalej\\Documents\\_Coding\\DragonRegen\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "print(project_root)\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from src.DataCreator.DataSets.DataSetGenStandard import DataSetGenStandard\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Test Data Set Generation\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6610aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actions': '    [action_id] IntegerType() NOT NULL,\\n    [name] StringType() NOT NULL,\\n    [description] StringType() NULL,\\n    [created_at] TimestampType() NOT NULL,\\n    [updated_at] TimestampType() NOT NULL,\\n    [status] StringType() NOT NULL,\\n    [error_code] StringType() NULL,\\n    [error_message] StringType() NULL,\\n    [error_timestamp] TimestampType() NULL,\\n    [metadata] StringType() NULL,\\n    CONSTRAINT [PK_actions] PRIMARY KEY CLUSTERED ([action_id])', 'sub_actions': '    [sub_action_id] IntegerType() NOT NULL,\\n    [action_id] IntegerType() NOT NULL,\\n    [name] StringType() NOT NULL,\\n    [description] StringType() NULL,\\n    [sequence_number] IntegerType() NOT NULL,\\n    [created_at] TimestampType() NOT NULL,\\n    [updated_at] TimestampType() NOT NULL,\\n    [status] StringType() NOT NULL,\\n    [error_code] StringType() NULL,\\n    [error_message] StringType() NULL,\\n    [error_timestamp] TimestampType() NULL,\\n    [metadata] StringType() NULL,\\n    CONSTRAINT [PK_sub_actions] PRIMARY KEY CLUSTERED ([sub_action_id])', 'requests': '    [request_id] IntegerType() NOT NULL,\\n    [sub_action_id] IntegerType() NOT NULL,\\n    [ai_service] StringType() NOT NULL,\\n    [endpoint] StringType() NOT NULL,\\n    [request_timestamp] TimestampType() NOT NULL,\\n    [response_timestamp] TimestampType() NULL,\\n    [duration_ms] IntegerType() NULL,\\n    [status_code] IntegerType() NULL,\\n    [request_parameters] StringType() NOT NULL,\\n    [raw_response] StringType() NULL,\\n    [parsed_results] StringType() NULL,\\n    [model_version] StringType() NULL,\\n    [completion_tokens] IntegerType() NULL,\\n    [prompt_tokens] IntegerType() NULL,\\n    [total_tokens] IntegerType() NULL,\\n    [cost] FloatType() NULL,\\n    [error_code] StringType() NULL,\\n    [error_message] StringType() NULL,\\n    [error_timestamp] TimestampType() NULL,\\n    [is_error_resolved] BooleanType() NULL,\\n    [resolution_notes] StringType() NULL,\\n    [metadata] StringType() NULL,\\n    CONSTRAINT [PK_requests] PRIMARY KEY CLUSTERED ([request_id])', 'metrics': '    [metric_id] IntegerType() NOT NULL,\\n    [action_id] IntegerType() NULL,\\n    [sub_action_id] IntegerType() NULL,\\n    [request_id] IntegerType() NULL,\\n    [metric_type] StringType() NOT NULL,\\n    [metric_name] StringType() NOT NULL,\\n    [value] FloatType() NOT NULL,\\n    [unit] StringType() NULL,\\n    [timestamp] TimestampType() NOT NULL,\\n    [dimensions] StringType() NULL,\\n    CONSTRAINT [PK_metrics] PRIMARY KEY CLUSTERED ([metric_id])'}\n"
     ]
    }
   ],
   "source": [
    "from src.DataCreator.SchemaGenerators.SchemaSpark import SchemaSpark\n",
    "from src.MetaFort.AILoggingTables import AILoggingTables\n",
    "\n",
    "s_sql_col = SchemaSpark.generate_schema_sql(AILoggingTables.d_system_tables)\n",
    "print(s_sql_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cd429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': StructType([StructField('metric_id', IntegerType(), False), StructField('action_id', IntegerType(), True), StructField('sub_action_id', IntegerType(), True), StructField('request_id', IntegerType(), True), StructField('metric_type', StringType(), False), StructField('metric_name', StringType(), False), StructField('value', FloatType(), False), StructField('unit', StringType(), True), StructField('timestamp', TimestampType(), False), StructField('dimensions', StringType(), True)])}\n",
      "StructType([StructField('metric_id', IntegerType(), False), StructField('action_id', IntegerType(), True), StructField('sub_action_id', IntegerType(), True), StructField('request_id', IntegerType(), True), StructField('metric_type', StringType(), False), StructField('metric_name', StringType(), False), StructField('value', FloatType(), False), StructField('unit', StringType(), True), StructField('timestamp', TimestampType(), False), StructField('dimensions', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "sturct_col = SchemaSpark.generate_schema(AILoggingTables.d_system_tables)\n",
    "print(sturct_col)\n",
    "print(sturct_col['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d685bd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructField('metric_id', IntegerType(), False)\n",
      "StructField('action_id', IntegerType(), True)\n",
      "StructField('sub_action_id', IntegerType(), True)\n",
      "StructField('request_id', IntegerType(), True)\n",
      "StructField('metric_type', StringType(), False)\n",
      "StructField('metric_name', StringType(), False)\n",
      "StructField('value', FloatType(), False)\n",
      "StructField('unit', StringType(), True)\n",
      "StructField('timestamp', TimestampType(), False)\n",
      "StructField('dimensions', StringType(), True)\n"
     ]
    }
   ],
   "source": [
    "for i in sturct_col['metrics']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe0d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------+----------+-----------+-----------+-----+----+---------+----------+\n",
      "|metric_id|action_id|sub_action_id|request_id|metric_type|metric_name|value|unit|timestamp|dimensions|\n",
      "+---------+---------+-------------+----------+-----------+-----------+-----+----+---------+----------+\n",
      "+---------+---------+-------------+----------+-----------+-----------+-----+----+---------+----------+\n",
      "\n",
      "root\n",
      " |-- metric_id: integer (nullable = false)\n",
      " |-- action_id: integer (nullable = true)\n",
      " |-- sub_action_id: integer (nullable = true)\n",
      " |-- request_id: integer (nullable = true)\n",
      " |-- metric_type: string (nullable = false)\n",
      " |-- metric_name: string (nullable = false)\n",
      " |-- value: float (nullable = false)\n",
      " |-- unit: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = false)\n",
      " |-- dimensions: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_metrics = spark.createDataFrame([],schema=sturct_col['metrics'])\n",
    "df_test_metrics.show(truncate=False)\n",
    "df_test_metrics.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd3f2f9",
   "metadata": {},
   "source": [
    "# MS SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ac8159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MS SQL Server database: MetaFort\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "driver = \"ODBC Driver 17 for SQL Server\"\n",
    "server = 'localhost\\\\SQLEXPRESS' \n",
    "# server = \"Andrew=PC\\\\SQLEXPRESS\"\n",
    "database = \"MetaFort\"\n",
    "conn_str = (\n",
    "    f\"DRIVER={driver};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    f\"Trusted_Connection=yes;\"\n",
    ")\n",
    "connection = pyodbc.connect(conn_str)\n",
    "cursor = connection.cursor()\n",
    "print(f\"Connected to MS SQL Server database: {database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bbde75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actions': '    [action_id] INT NOT NULL,\\n    [name] NVARCHAR(255) NOT NULL,\\n    [description] NVARCHAR(255) NULL,\\n    [created_at] DATETIME2 NOT NULL,\\n    [updated_at] DATETIME2 NOT NULL,\\n    [status] NVARCHAR(255) NOT NULL,\\n    [error_code] NVARCHAR(255) NULL,\\n    [error_message] NVARCHAR(255) NULL,\\n    [error_timestamp] DATETIME2 NULL,\\n    [metadata] NVARCHAR(MAX) NULL,\\n    CONSTRAINT [PK_actions] PRIMARY KEY CLUSTERED ([action_id])', 'sub_actions': '    [sub_action_id] INT NOT NULL,\\n    [action_id] INT NOT NULL,\\n    [name] NVARCHAR(255) NOT NULL,\\n    [description] NVARCHAR(255) NULL,\\n    [sequence_number] INT NOT NULL,\\n    [created_at] DATETIME2 NOT NULL,\\n    [updated_at] DATETIME2 NOT NULL,\\n    [status] NVARCHAR(255) NOT NULL,\\n    [error_code] NVARCHAR(255) NULL,\\n    [error_message] NVARCHAR(255) NULL,\\n    [error_timestamp] DATETIME2 NULL,\\n    [metadata] NVARCHAR(MAX) NULL,\\n    CONSTRAINT [PK_sub_actions] PRIMARY KEY CLUSTERED ([sub_action_id])', 'requests': '    [request_id] INT NOT NULL,\\n    [sub_action_id] INT NOT NULL,\\n    [ai_service] NVARCHAR(255) NOT NULL,\\n    [endpoint] NVARCHAR(255) NOT NULL,\\n    [request_timestamp] DATETIME2 NOT NULL,\\n    [response_timestamp] DATETIME2 NULL,\\n    [duration_ms] INT NULL,\\n    [status_code] INT NULL,\\n    [request_parameters] NVARCHAR(MAX) NOT NULL,\\n    [raw_response] NVARCHAR(MAX) NULL,\\n    [parsed_results] NVARCHAR(MAX) NULL,\\n    [model_version] NVARCHAR(255) NULL,\\n    [completion_tokens] INT NULL,\\n    [prompt_tokens] INT NULL,\\n    [total_tokens] INT NULL,\\n    [cost] FLOAT NULL,\\n    [error_code] NVARCHAR(255) NULL,\\n    [error_message] NVARCHAR(255) NULL,\\n    [error_timestamp] DATETIME2 NULL,\\n    [is_error_resolved] BIT NULL,\\n    [resolution_notes] NVARCHAR(255) NULL,\\n    [metadata] NVARCHAR(MAX) NULL,\\n    CONSTRAINT [PK_requests] PRIMARY KEY CLUSTERED ([request_id])', 'metrics': '    [metric_id] INT NOT NULL,\\n    [action_id] INT NULL,\\n    [sub_action_id] INT NULL,\\n    [request_id] INT NULL,\\n    [metric_type] NVARCHAR(255) NOT NULL,\\n    [metric_name] NVARCHAR(255) NOT NULL,\\n    [value] FLOAT NOT NULL,\\n    [unit] NVARCHAR(255) NULL,\\n    [timestamp] DATETIME2 NOT NULL,\\n    [dimensions] NVARCHAR(MAX) NULL,\\n    CONSTRAINT [PK_metrics] PRIMARY KEY CLUSTERED ([metric_id])'}\n"
     ]
    }
   ],
   "source": [
    "from src.DataCreator.SchemaGenerators.SchemaMSSQL import SchemaMSSQL\n",
    "from src.MetaFort.AILoggingTables import AILoggingTables\n",
    "\n",
    "s_sql_col = SchemaMSSQL.generate_schema_sql(AILoggingTables.d_system_tables)\n",
    "print(s_sql_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8fcb387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "\n",
      "        if OBJECT_ID('dbo.actions', 'U') IS NULL\n",
      "        CREATE TABLE dbo.actions (    [action_id] INT NOT NULL,\n",
      "    [name] NVARCHAR(255) NOT NULL,\n",
      "    [description] NVARCHAR(255) NULL,\n",
      "    [created_at] DATETIME2 NOT NULL,\n",
      "    [updated_at] DATETIME2 NOT NULL,\n",
      "    [status] NVARCHAR(255) NOT NULL,\n",
      "    [error_code] NVARCHAR(255) NULL,\n",
      "    [error_message] NVARCHAR(255) NULL,\n",
      "    [error_timestamp] DATETIME2 NULL,\n",
      "    [metadata] NVARCHAR(MAX) NULL,\n",
      "    CONSTRAINT [PK_actions] PRIMARY KEY CLUSTERED ([action_id]))\n",
      "        ;\n",
      "====================\n",
      "\n",
      "        if OBJECT_ID('dbo.sub_actions', 'U') IS NULL\n",
      "        CREATE TABLE dbo.sub_actions (    [sub_action_id] INT NOT NULL,\n",
      "    [action_id] INT NOT NULL,\n",
      "    [name] NVARCHAR(255) NOT NULL,\n",
      "    [description] NVARCHAR(255) NULL,\n",
      "    [sequence_number] INT NOT NULL,\n",
      "    [created_at] DATETIME2 NOT NULL,\n",
      "    [updated_at] DATETIME2 NOT NULL,\n",
      "    [status] NVARCHAR(255) NOT NULL,\n",
      "    [error_code] NVARCHAR(255) NULL,\n",
      "    [error_message] NVARCHAR(255) NULL,\n",
      "    [error_timestamp] DATETIME2 NULL,\n",
      "    [metadata] NVARCHAR(MAX) NULL,\n",
      "    CONSTRAINT [PK_sub_actions] PRIMARY KEY CLUSTERED ([sub_action_id]))\n",
      "        ;\n",
      "====================\n",
      "\n",
      "        if OBJECT_ID('dbo.requests', 'U') IS NULL\n",
      "        CREATE TABLE dbo.requests (    [request_id] INT NOT NULL,\n",
      "    [sub_action_id] INT NOT NULL,\n",
      "    [ai_service] NVARCHAR(255) NOT NULL,\n",
      "    [endpoint] NVARCHAR(255) NOT NULL,\n",
      "    [request_timestamp] DATETIME2 NOT NULL,\n",
      "    [response_timestamp] DATETIME2 NULL,\n",
      "    [duration_ms] INT NULL,\n",
      "    [status_code] INT NULL,\n",
      "    [request_parameters] NVARCHAR(MAX) NOT NULL,\n",
      "    [raw_response] NVARCHAR(MAX) NULL,\n",
      "    [parsed_results] NVARCHAR(MAX) NULL,\n",
      "    [model_version] NVARCHAR(255) NULL,\n",
      "    [completion_tokens] INT NULL,\n",
      "    [prompt_tokens] INT NULL,\n",
      "    [total_tokens] INT NULL,\n",
      "    [cost] FLOAT NULL,\n",
      "    [error_code] NVARCHAR(255) NULL,\n",
      "    [error_message] NVARCHAR(255) NULL,\n",
      "    [error_timestamp] DATETIME2 NULL,\n",
      "    [is_error_resolved] BIT NULL,\n",
      "    [resolution_notes] NVARCHAR(255) NULL,\n",
      "    [metadata] NVARCHAR(MAX) NULL,\n",
      "    CONSTRAINT [PK_requests] PRIMARY KEY CLUSTERED ([request_id]))\n",
      "        ;\n",
      "====================\n",
      "\n",
      "        if OBJECT_ID('dbo.metrics', 'U') IS NULL\n",
      "        CREATE TABLE dbo.metrics (    [metric_id] INT NOT NULL,\n",
      "    [action_id] INT NULL,\n",
      "    [sub_action_id] INT NULL,\n",
      "    [request_id] INT NULL,\n",
      "    [metric_type] NVARCHAR(255) NOT NULL,\n",
      "    [metric_name] NVARCHAR(255) NOT NULL,\n",
      "    [value] FLOAT NOT NULL,\n",
      "    [unit] NVARCHAR(255) NULL,\n",
      "    [timestamp] DATETIME2 NOT NULL,\n",
      "    [dimensions] NVARCHAR(MAX) NULL,\n",
      "    CONSTRAINT [PK_metrics] PRIMARY KEY CLUSTERED ([metric_id]))\n",
      "        ;\n"
     ]
    }
   ],
   "source": [
    "output = SchemaMSSQL.create_tables_from_dict(db_engine=cursor, d_tables=s_sql_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ab8d3",
   "metadata": {},
   "source": [
    "### Close Connection when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc00ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
