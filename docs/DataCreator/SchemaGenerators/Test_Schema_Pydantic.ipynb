{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae28ba27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalej\\Documents\\_Coding\\DragonRegen\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_dir = os.path.abspath(os.path.join(notebook_dir, '..', '..', '..'))\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "print(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85b1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DataCreator.SchemaGenerators.SchemaPydantic import SchemaPydantic\n",
    "from src.MetaFort.AILoggingTopics import AILoggingTopics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7c71e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Pydantic Class:\n",
      "==================================================\n",
      "from pydantic import BaseModel, Field\n",
      "from typing import Optional, List, Dict, Any\n",
      "from datetime import datetime\n",
      "\n",
      "\n",
      "class LLMRequest(BaseModel):\n",
      "    request_id: int = Field(..., description=\"Primary key, unique identifier for the request\")\n",
      "    task_id: int = Field(..., description=\"Foreign key referencing the task log\")\n",
      "    insert_dt: datetime = Field(..., description=\"When the request was logged.\")\n",
      "    status: Optional[str] = None\n",
      "    ai_service: str = Field(..., description=\"Name or identifier of the AI service being called\")\n",
      "    model: str = Field(..., description=\"Version of the AI model used (if applicable)\")\n",
      "    request_parameters: Optional[Dict[str, Any]] = None\n",
      "    user_prompt: Optional[str] = None\n",
      "    engineered_prompt: Optional[str] = None\n",
      "    api_request_id: Optional[str] = None\n",
      "    raw_response: Optional[Dict[str, Any]] = None\n",
      "    parsed_results: Optional[Dict[str, Any]] = None\n",
      "    response_metadate: Optional[Dict[str, Any]] = None\n",
      "    input_tokens: Optional[int] = None\n",
      "    output_tokens: Optional[int] = None\n",
      "    request_timestamp: Optional[datetime] = None\n",
      "    response_timestamp: Optional[datetime] = None\n",
      "    duration_ms: Optional[int] = None\n",
      "    error_code: Optional[str] = None\n",
      "    error_message: Optional[str] = None\n",
      "    error_timestamp: Optional[datetime] = None\n",
      "    retry_cnt: Optional[int] = None\n",
      "    RAG_Embeding_Model: Optional[Dict[str, Any]] = None\n",
      "    RAG_IDs: Optional[Dict[str, Any]] = None\n",
      "    RAG_Versions: Optional[Dict[str, Any]] = None\n",
      "    metadata: Optional[Dict[str, Any]] = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# columns = AILoggingTopics.d_system_topics[AILoggingTopics.AI_TASK_TOPIC]['fields']\n",
    "# columns = AILoggingTopics.d_system_topics[AILoggingTopics.AI_TASK_COMPLETED_TOPIC]['fields']\n",
    "columns = AILoggingTopics.d_system_topics[AILoggingTopics.AI_REQUEST_LOG_TOPIC]['fields']\n",
    "pydantic_code = SchemaPydantic.generate_pydantic_class(columns, \"LLMRequest\")\n",
    "\n",
    "# Print the generated code\n",
    "print(\"Generated Pydantic Class:\")\n",
    "print(\"=\" * 50)\n",
    "print(pydantic_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11dee6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Pydantic Class:\n",
      "==================================================\n",
      "from pydantic import BaseModel, Field\n",
      "from typing import Optional, List, Dict, Any\n",
      "from datetime import datetime\n",
      "\n",
      "\n",
      "class Artifact(BaseModel):\n",
      "    artifactId: int = Field(..., description=\"Primary key, unique identifier for an artifact produced by a task\")\n",
      "    task_id: int = Field(..., description=\"Foreign key, representing a specific task\")\n",
      "    group_task_id: Optional[int] = None\n",
      "    insert_dt: datetime = Field(..., description=\"Timestamp when the task was completed\")\n",
      "    name: str = Field(..., description=\"Name of the task\")\n",
      "    description: Optional[Dict[str, Any]] = None\n",
      "    parts: List[Any] = Field(..., description=\"Content of the artifact, as one or more Part objects. Must have at least one.\")\n",
      "    metadata: Optional[Dict[str, Any]] = None\n",
      "    extensions: Optional[Dict[str, Any]] = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column definitions from your input\n",
    "columns = [\n",
    "{\"name\": \"artifactId\", \"type\": \"Integer\", \"nullable\": False, \"metadata\": {\"description\": \"Primary key, unique identifier for an artifact produced by a task\"}},\n",
    "{\"name\": \"task_id\", \"type\": \"Integer\", \"nullable\": False, \"metadata\": {\"description\": \"Foreign key, representing a specific task\"}},\n",
    "{\"name\": \"group_task_id\", \"type\": \"Integer\", \"nullable\": True, \"metadata\": {\"description\": \"Name of the a set of tasks that chained off each other. The value is the root task ID\"}},\n",
    "{\"name\": \"insert_dt\", \"type\": \"Timestamp\", \"nullable\": False, \"metadata\": {\"description\": \"Timestamp when the task was completed\"}},\n",
    "{\"name\": \"name\", \"type\": \"String\", \"nullable\": False, \"metadata\": {\"description\": \"Name of the task\"}},\n",
    "{\"name\": \"description\", \"type\": \"JSON\", \"nullable\": True, \"metadata\": {\"description\": \"Human-readable description of the artifact.\"}},\n",
    "{\"name\": \"parts\", \"type\": \"Array\", \"nullable\": False, \"metadata\": {\"description\": \"Content of the artifact, as one or more Part objects. Must have at least one.\"}},\n",
    "{\"name\": \"metadata\", \"type\": \"JSON\", \"nullable\": True, \"metadata\": {\"description\": \"Arbitrary key-value metadata associated with the artifact.\"}},\n",
    "{\"name\": \"extensions\", \"type\": \"JSON\", \"nullable\": True, \"metadata\": {\"description\": \"A list of extension URIs that contributed to this artifact.\"}}\n",
    "]\n",
    "# Generate the Pydantic class\n",
    "pydantic_code = SchemaPydantic.generate_pydantic_class(columns, \"Artifact\")\n",
    "\n",
    "# Print the generated code\n",
    "print(\"Generated Pydantic Class:\")\n",
    "print(\"=\" * 50)\n",
    "print(pydantic_code)\n",
    "\n",
    "# # Optionally save to file\n",
    "# with open(\"artifact_model.py\", \"w\") as f:\n",
    "#     f.write(pydantic_code)\n",
    "\n",
    "# print(\"Code saved to 'artifact_model.py'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kafka_Spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
