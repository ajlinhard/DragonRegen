


---
# Routing Tables of Data
---
- Data Source 1
- Data Source 3
- Link Engine
    - Spark
    - pyodbc
    - kafka
    - Structure links as builder or factory style subpackage

### Simulate Fake Data Production
The data can be make by spark for large data sets
- handling incremental data chunks
- distribute over buckets via distribution mapping (ex: days of the week with diff volumes of records)
- kafka sims could be prepped and the released in little chunks


### Automation Assist


---
# AI building
---


## Fake Data Creation
- Produce layout, refine columns + metadata, generate

## Pipelines
- Generate via column meta data and request.


