{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Setup\n",
    "1. Build Spark Session\n",
    "2. Build Cassandra Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "s_conn = None\n",
    "s_conn = SparkSession.builder \\\n",
    "    .appName('SparkDataStreaming') \\\n",
    "    .config('spark.jars.packages', \"com.datastax.spark:spark-cassandra-connector_2.12:3.4.1,\"\n",
    "                                    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1\") \\\n",
    "    .config('spark.cassandra.connection.host', 'localhost') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "s_conn.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# connecting to the cassandra cluster\n",
    "try:\n",
    "    cluster = Cluster(['localhost'])\n",
    "\n",
    "    cas_session = cluster.connect()\n",
    "except Exception as e:\n",
    "    logging.error(f\"Could not create cassandra connection due to {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Contruct the Expected Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"first_name\", StringType(), False),\n",
    "    StructField(\"last_name\", StringType(), False),\n",
    "    StructField(\"gender\", StringType(), False),\n",
    "    StructField(\"address\", StringType(), False),\n",
    "    StructField(\"post_code\", StringType(), False),\n",
    "    StructField(\"email\", StringType(), False),\n",
    "    StructField(\"username\", StringType(), False),\n",
    "    StructField(\"registered_date\", StringType(), False),\n",
    "    StructField(\"phone\", StringType(), False),\n",
    "    StructField(\"picture\", StringType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyspace created successfully!\n"
     ]
    }
   ],
   "source": [
    "cas_session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS spark_streams\n",
    "    WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};\n",
    "\"\"\")\n",
    "\n",
    "print(\"Keyspace created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_view_df = s_conn.readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', 'localhost:9092') \\\n",
    "    .option('subscribe', 'users_created') \\\n",
    "    .option('startingOffsets', 'latest') \\\n",
    "    .load()\n",
    "spark_select_df = spark_view_df.selectExpr(\"CAST(value AS STRING)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_select_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .option(\"numRows\", 50) \\\n",
    "    .start()\n",
    "\n",
    "query = None # Initialize to insure we can check if it was started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03a Experiment: Consume Stream query in a Notebook\n",
    "### Results:\n",
    "You can write the stream to \"memory\" with function \".format\", then name the query in memory to be accessed later via a Spark-SQL query.\n",
    "Use \".show()\", \".head(10)\" or \".collect()\" to pull the query into a usable or viewable data set.\n",
    "\n",
    "### Notes:\n",
    "    - If you recreate the writeStream aka variable \"spark_select_df\" then the queryName = \"streaming_df\" will already exists and fail.\n",
    "    - Also, if you recreate the readStream , then since the stream already consumed the data then nothing will show up.\n",
    "        - Only true, if the startingOffset is set to \"latest\" and not \"earliest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query already active\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(value='{\"id\": 228627584116828766513234465659512718569, \"first_name\": \"Ridwan\", \"last_name\": \"Aga\", \"gender\": \"male\", \"address\": \"4417 \\\\u00d8vre Ullern terrasse, Fagernes, Troms - Romsa, Norway\", \"post_code\": \"4003\", \"email\": \"ridwan.aga@example.com\", \"username\": \"blackkoala405\", \"dob\": \"1987-02-11T21:29:24.669Z\", \"registered_date\": \"2013-04-18T09:59:05.607Z\", \"phone\": \"64108927\", \"picture\": \"https://randomuser.me/api/portraits/med/men/12.jpg\"}'),\n",
       " Row(value='{\"id\": 36548244493338199433306678270268393268, \"first_name\": \"Ernesto\", \"last_name\": \"Fuentes\", \"gender\": \"male\", \"address\": \"1962 Calle de Bravo Murillo, Parla, Melilla, Spain\", \"post_code\": 23576, \"email\": \"ernesto.fuentes@example.com\", \"username\": \"smallgorilla441\", \"dob\": \"1948-05-28T20:11:06.089Z\", \"registered_date\": \"2022-01-28T09:57:57.803Z\", \"phone\": \"972-304-465\", \"picture\": \"https://randomuser.me/api/portraits/med/men/36.jpg\"}')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if query is not None and query.isActive:\n",
    "    print('Query already active')\n",
    "else:\n",
    "    query = spark_select_df.writeStream \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .queryName(\"streaming_df7\").start()\n",
    "\n",
    "# To view the results, you can then query the in-memory table\n",
    "s_conn.sql(\"SELECT * FROM streaming_df7\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='{\"id\": 247817924588245923341384306894570166991, \"first_name\": \"Ida\", \"last_name\": \"Nguyen\", \"gender\": \"female\", \"address\": \"8085 Pockrus Page Rd, Roseville, California, United States\", \"post_code\": 36146, \"email\": \"ida.nguyen@example.com\", \"username\": \"redlion718\", \"dob\": \"1982-08-07T00:02:02.743Z\", \"registered_date\": \"2009-05-16T23:40:21.802Z\", \"phone\": \"(477) 278-5931\", \"picture\": \"https://randomuser.me/api/portraits/med/women/10.jpg\"}'),\n",
       " Row(value='{\"id\": 174284896883338618945951761980772274025, \"first_name\": \"L\\\\u00e6rke\", \"last_name\": \"Larsen\", \"gender\": \"female\", \"address\": \"2738 Poppel Alle, K\\\\u00f8benhavn V, Sj\\\\u00e6lland, Denmark\", \"post_code\": 83832, \"email\": \"laerke.larsen@example.com\", \"username\": \"bigfrog983\", \"dob\": \"1963-09-02T22:01:34.412Z\", \"registered_date\": \"2017-02-01T01:27:03.264Z\", \"phone\": \"85613719\", \"picture\": \"https://randomuser.me/api/portraits/med/women/31.jpg\"}'),\n",
       " Row(value='{\"id\": 214859958238539815279719897260767091546, \"first_name\": \"Myrtle\", \"last_name\": \"Gomez\", \"gender\": \"female\", \"address\": \"6048 White Oak Dr, Wagga Wagga, South Australia, Australia\", \"post_code\": 7148, \"email\": \"myrtle.gomez@example.com\", \"username\": \"crazyswan728\", \"dob\": \"1961-08-27T03:38:08.921Z\", \"registered_date\": \"2005-05-30T23:15:56.864Z\", \"phone\": \"04-6031-7951\", \"picture\": \"https://randomuser.me/api/portraits/med/women/66.jpg\"}'),\n",
       " Row(value='{\"id\": 236009374668639520510111894967313824462, \"first_name\": \"Kadir\", \"last_name\": \"K\\\\u00fc\\\\u00e7\\\\u00fckler\", \"gender\": \"male\", \"address\": \"706 Fatih Sultan Mehmet Cd, Erzurum, Tekirda\\\\u011f, Turkey\", \"post_code\": 12114, \"email\": \"kadir.kucukler@example.com\", \"username\": \"organicladybug806\", \"dob\": \"1997-03-05T02:42:16.644Z\", \"registered_date\": \"2009-05-14T09:43:28.719Z\", \"phone\": \"(544)-981-3891\", \"picture\": \"https://randomuser.me/api/portraits/med/men/34.jpg\"}'),\n",
       " Row(value='{\"id\": 249282405535338182319800648360079631804, \"first_name\": \"Vitali\", \"last_name\": \"Wieser\", \"gender\": \"male\", \"address\": \"7261 Kirchweg, Rauenberg, Bayern, Germany\", \"post_code\": 33140, \"email\": \"vitali.wieser@example.com\", \"username\": \"beautifulcat477\", \"dob\": \"1992-08-08T07:08:17.990Z\", \"registered_date\": \"2014-03-09T03:52:54.151Z\", \"phone\": \"0503-3406179\", \"picture\": \"https://randomuser.me/api/portraits/med/men/30.jpg\"}')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_conn.sql(\"SELECT * FROM streaming_df\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03b Experiment: Read from the same stream under a different behavior.\n",
    "Result: The stream will be empty as long as no new records were produced on the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_same_stream = spark_select_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"streaming_same_df\").start()\n",
    "\n",
    "# To view the results, you can then query the in-memory table\n",
    "s_conn.sql(\"SELECT * FROM streaming_same_df\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Stream into a new dataframe with JSON parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = s_conn.readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', 'localhost:9092') \\\n",
    "    .option('subscribe', 'users_created') \\\n",
    "    .option('startingOffsets', 'earliest') \\\n",
    "    .load()\n",
    "\n",
    "sel = spark_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col('value'), schema).alias('data')).select(\"data.*\")\n",
    "print(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully!\n"
     ]
    }
   ],
   "source": [
    "s_table_name = 'created_users1'\n",
    "cas_session.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS spark_streams.{s_table_name} (\n",
    "        id TEXT PRIMARY KEY,\n",
    "        first_name TEXT,\n",
    "        last_name TEXT,\n",
    "        gender TEXT,\n",
    "        address TEXT,\n",
    "        post_code TEXT,\n",
    "        email TEXT,\n",
    "        username TEXT,\n",
    "        registered_date TEXT,\n",
    "        phone TEXT,\n",
    "        picture TEXT);\n",
    "\"\"\")\n",
    "\n",
    "print(\"Table created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_query = (sel.writeStream.format(\"org.apache.spark.sql.cassandra\")\n",
    "                               .option('checkpointLocation', '/tmp/checkpoint')\n",
    "                               .option('keyspace', 'spark_streams')\n",
    "                               .option('table', 'created_users2')\n",
    "                               .start())\n",
    "\n",
    "streaming_query.isActive()\n",
    "# streaming_query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kafka_Spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
